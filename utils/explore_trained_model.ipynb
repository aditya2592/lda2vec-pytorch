{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1d97d4229bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMulticoreTSNE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticoreTSNE\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlda2vec_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data_big/mlp/custom_lda2vec/lda2vec-pytorch/utils/lda2vec_loss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mortho_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malias_multinomial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAliasMultinomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/DmitryUlyanov/Multicore-TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "from lda2vec_loss import loss, topic_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # x has shape [batch_size, n_classes]\n",
    "    e = np.exp(x)\n",
    "    n = np.sum(e, 1, keepdims=True)\n",
    "    return e/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "# docs = dataset['data']\n",
    "\n",
    "# store each document with an initial id\n",
    "# docs = [(i, doc) for i, doc in enumerate(docs)]\n",
    "\n",
    "# \"integer -> word\" decoder \n",
    "decoder = np.load('decoder.npy')[()]\n",
    "\n",
    "# for restoring document ids, \"id used while training -> initial id\"\n",
    "doc_decoder = np.load('doc_decoder.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original document categories\n",
    "# targets = dataset['target']\n",
    "# target_names = dataset['target_names']\n",
    "# targets = np.array([targets[doc_decoder[i]] for i in range(len(doc_decoder))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-32967d9a723a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../stance/test_data.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_state.pytorch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = np.load('../stance/test_data.npy')\n",
    "\n",
    "model = loss(*args, **kwargs)\n",
    "\n",
    "state = torch.load('model_state.pytorch', map_location=lambda storage, loc: storage)\n",
    "n_topics = 25\n",
    "\n",
    "doc_weights = state['doc_weights.weight'].cpu().clone().numpy()\n",
    "topic_vectors = state['topics.topic_vectors'].cpu().clone().numpy()\n",
    "resulted_word_vectors = state['neg.embedding.weight'].cpu().clone().numpy()\n",
    "\n",
    "# distribution over the topics for each document\n",
    "topic_dist = softmax(doc_weights)\n",
    "\n",
    "# vector representation of the documents\n",
    "doc_vecs = np.matmul(topic_dist, topic_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.matmul(topic_vectors, resulted_word_vectors.T)\n",
    "most_similar = similarity.argsort(axis=1)[:, -30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "msl = list(map((lambda x: set(x)), most_similar.tolist()))\n",
    "ints = set.intersection(*msl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 16, 18, 20, 22, 23, 34}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_n = list(map((lambda x: list(x - ints)), msl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 6, 40, 15, 49, 21, 53, 25, 26, 30, 31],\n",
       " [64, 33, 35, 6, 40, 12, 15, 19, 21, 25, 30],\n",
       " [64, 35, 6, 43, 12, 17, 19, 21, 54, 25, 27],\n",
       " [33, 6, 40, 12, 15, 17, 19, 21, 25, 26, 28],\n",
       " [33, 65, 35, 6, 40, 15, 48, 19, 21, 24, 31],\n",
       " [35, 6, 40, 12, 15, 19, 21, 24, 25, 26, 28],\n",
       " [35, 6, 40, 12, 15, 48, 19, 21, 25, 30, 31],\n",
       " [32, 65, 35, 40, 12, 45, 46, 15, 82, 21, 30],\n",
       " [37, 6, 40, 74, 12, 50, 19, 21, 26, 28, 30],\n",
       " [33, 35, 37, 40, 15, 21, 25, 26, 28, 30, 31],\n",
       " [35, 37, 6, 12, 15, 48, 17, 19, 21, 25, 27],\n",
       " [33, 37, 6, 40, 15, 50, 19, 21, 25, 28, 30],\n",
       " [35, 58, 40, 42, 15, 21, 53, 24, 26, 30, 31],\n",
       " [64, 35, 6, 40, 43, 12, 15, 19, 21, 54, 25],\n",
       " [6, 40, 12, 17, 50, 19, 21, 25, 26, 28, 29],\n",
       " [35, 6, 40, 43, 12, 15, 17, 19, 21, 25, 26],\n",
       " [65, 35, 40, 12, 15, 17, 21, 24, 57, 26, 28],\n",
       " [35, 6, 12, 15, 48, 51, 24, 25, 27, 30, 31],\n",
       " [64, 35, 6, 40, 43, 12, 15, 19, 21, 24, 25],\n",
       " [35, 6, 15, 48, 50, 51, 21, 24, 26, 30, 31],\n",
       " [33, 6, 40, 12, 17, 50, 19, 21, 24, 25, 28],\n",
       " [33, 69, 40, 12, 17, 50, 19, 24, 25, 26, 28],\n",
       " [64, 35, 6, 40, 15, 21, 53, 57, 26, 30, 31],\n",
       " [64, 33, 35, 6, 40, 12, 15, 19, 21, 25, 26],\n",
       " [64, 35, 6, 43, 15, 48, 21, 53, 25, 30, 31]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1 : candidate run time comment presidential good new republican come nbc tell\n",
      "topic 2 : run comment good mexico republican immigrant come nbc tell love dump\n",
      "topic 3 : immigration comment cut good mexico illegal immigrant tie nbc tell dump\n",
      "topic 4 : american time comment good mexico illegal republican immigrant come nbc love\n",
      "topic 5 : candidate right good mexico speak republican come nbc tell hair love\n",
      "topic 6 : american time comment right good mexico republican immigrant come nbc tell\n",
      "topic 7 : candidate run comment good mexico speak republican immigrant come nbc tell\n",
      "topic 8 : run good week republican support look immigrant come tell hair word\n",
      "topic 9 : run american time good mexico country immigrant big come nbc great\n",
      "topic 10 : candidate run american time comment good republican come great tell love\n",
      "topic 11 : immigration comment good mexico illegal speak republican immigrant nbc great tell\n",
      "topic 12 : run american comment good mexico country republican come nbc great love\n",
      "topic 13 : candidate run time right presidential good republican win come thing tell\n",
      "topic 14 : comment cut good mexico republican immigrant tie come nbc tell dump\n",
      "topic 15 : usa american time comment good mexico country illegal immigrant come nbc\n",
      "topic 16 : time comment good mexico illegal republican immigrant tie come nbc tell\n",
      "topic 17 : american time campaign right good illegal republican immigrant come tell hair\n",
      "topic 18 : candidate run immigration comment right truth speak republican immigrant nbc tell\n",
      "topic 19 : comment right good mexico republican immigrant tie come nbc tell dump\n",
      "topic 20 : candidate run time right good truth country speak republican nbc tell\n",
      "topic 21 : american comment right good mexico country illegal immigrant come nbc love\n",
      "topic 22 : american time comment right mexico country illegal immigrant come call love\n",
      "topic 23 : candidate run time campaign presidential good republican come nbc tell dump\n",
      "topic 24 : time comment good mexico republican immigrant come nbc tell love dump\n",
      "topic 25 : candidate run comment presidential good speak republican tie nbc tell dump\n"
     ]
    }
   ],
   "source": [
    "# similarity = np.matmul(topic_vectors, resulted_word_vectors.T)\n",
    "# most_similar = similarity.argsort(axis=1)[:, -10:]\n",
    "\n",
    "for j in range(n_topics):\n",
    "#     topic_words_list = \n",
    "    topic_words = ' '.join([decoder[i] for i in reversed(most_similar_n[j])])\n",
    "    print('topic', j + 1, ':', topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show learned document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "X = tsne.fit_transform(doc_vecs.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X):\n",
    "    # X has shape [n_documents, 2]\n",
    "    \n",
    "    plt.figure(figsize=(16, 9), dpi=120);\n",
    "    cmap = plt.cm.tab20\n",
    "    number_of_targets = 20\n",
    "    \n",
    "    for i in range(number_of_targets):\n",
    "        \n",
    "        label = target_names[i]\n",
    "        size = 15.0\n",
    "        linewidths = 0.5\n",
    "        edgecolors = 'k'\n",
    "        color = cmap(i)\n",
    "        \n",
    "        if 'comp' in label:\n",
    "            marker = 'x'\n",
    "        elif 'sport' in label:\n",
    "            marker = 's'\n",
    "            edgecolors = 'b'\n",
    "        elif 'politics' in label:\n",
    "            marker = 'o'\n",
    "            edgecolors = 'g'\n",
    "        elif 'religion' in label:\n",
    "            marker = 'P'\n",
    "            size = 17.0\n",
    "        elif 'sci' in label:\n",
    "            marker = 'o'\n",
    "            size = 14.0\n",
    "            edgecolors = 'k'\n",
    "            linewidths = 1.0\n",
    "        elif 'atheism' in label:\n",
    "            marker = 'P'\n",
    "            size = 18.0\n",
    "            edgecolors = 'r'\n",
    "            linewidths = 0.5\n",
    "        else:\n",
    "            marker = 'v'\n",
    "            edgecolors = 'm'\n",
    "        \n",
    "        plt.scatter(\n",
    "            X[targets == i, 0], \n",
    "            X[targets == i, 1], \n",
    "            s=size, c=color, marker=marker,\n",
    "            linewidths=linewidths, edgecolors=edgecolors,\n",
    "            label=label\n",
    "        );\n",
    "    \n",
    "    leg = plt.legend()\n",
    "    leg.get_frame().set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 46878 but corresponding boolean dimension is 18846",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-66e86b6c82cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# learned document vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# different colors and markers represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ground truth labels of each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-28ea0ed53265>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         plt.scatter(\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 46878 but corresponding boolean dimension is 18846"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1920x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(X)  # learned document vectors\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show initial document weights (vanilla lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_weights_init = np.load('doc_weights_init.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "Y = tsne.fit_transform(doc_weights_init.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to initialize topic assignments for lda2vec algorithm \n",
    "# I run normal LDA and used output distributions over topics \n",
    "# of each document\n",
    "\n",
    "plot(Y)  # distribution over the topics for each document (output of LDA)\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore learned topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "Z = tsne.fit_transform(topic_dist.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Z)  # learned distribution over the topics for each document\n",
    "\n",
    "# these are topic assignments as on the plot above \n",
    "# but these ones are after the training of lda2vec\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of nonzero probabilities\n",
    "dist = topic_dist.reshape(-1)\n",
    "plt.hist(dist[dist > 0.01], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of probabilities for some random topic\n",
    "plt.hist(topic_dist[:, 10], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic assignments for two random topics\n",
    "plt.scatter(topic_dist[:, 10], topic_dist[:, 20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of topic assignments\n",
    "corr = np.corrcoef(topic_dist.transpose(1, 0))\n",
    "plt.imshow(corr);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show a document and its topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 100 # document id\n",
    "\n",
    "print('DOCUMENT:')\n",
    "print([doc for j, doc in docs if j == doc_decoder[i]][0], '\\n')\n",
    "\n",
    "print('DISTRIBUTION OVER TOPICS:')\n",
    "s = ''\n",
    "for j, p in enumerate(topic_dist[i], 1):\n",
    "    s += '{0}:{1:.3f}  '.format(j, p)\n",
    "    if j%6 == 0:\n",
    "        s += '\\n'\n",
    "print(s)\n",
    "\n",
    "print('\\nTOP TOPICS:')\n",
    "for j in reversed(topic_dist[i].argsort()[-3:]):\n",
    "    topic_words = ' '.join([decoder[i] for i in reversed(most_similar[j])])\n",
    "    print('topic', j + 1, ':', topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
