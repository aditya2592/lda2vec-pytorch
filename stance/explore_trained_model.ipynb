{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/DmitryUlyanov/Multicore-TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'.')\n",
    "sys.path.insert(0,'/data_big/mlp/custom_lda2vec/lda2vec-pytorch')\n",
    "\n",
    "from utils.lda2vec_loss import loss, topic_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # x has shape [batch_size, n_classes]\n",
    "    e = np.exp(x)\n",
    "    n = np.sum(e, 1, keepdims=True)\n",
    "    return e/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "# docs = dataset['data']\n",
    "\n",
    "# store each document with an initial id\n",
    "# docs = [(i, doc) for i, doc in enumerate(docs)]\n",
    "\n",
    "docs = np.load('docs.npy')\n",
    "# \"integer -> word\" decoder \n",
    "decoder = np.load('decoder.npy')[()]\n",
    "\n",
    "# for restoring document ids, \"id used while training -> initial id\"\n",
    "doc_decoder = np.load('doc_decoder.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original document categories\n",
    "# targets = dataset['target']\n",
    "# target_names = dataset['target_names']\n",
    "# targets = np.array([targets[doc_decoder[i]] for i in range(len(doc_decoder))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = np.load('test_data.npy')\n",
    "# batch = torch.from_numpy(test_data).cuda()\n",
    "\n",
    "# doc_indices = batch[:, 0]\n",
    "# pivot_words = batch[:, 1]\n",
    "# target_words = batch[:, 2:]\n",
    "            \n",
    "# model = torch.load('model.pytorch')\n",
    "# model.eval()\n",
    "# test_doc_vectors = model(doc_indices, pivot_words, target_words)\n",
    "# print(test_doc_vectors)\n",
    "\n",
    "state = torch.load('model_state.pytorch', map_location=lambda storage, loc: storage)\n",
    "n_topics = 10\n",
    "\n",
    "doc_weights = state['doc_weights.weight'].cpu().clone().numpy()\n",
    "topic_vectors = state['topics.topic_vectors'].cpu().clone().numpy()\n",
    "resulted_word_vectors = state['neg.embedding.weight'].cpu().clone().numpy()\n",
    "\n",
    "# distribution over the topics for each document\n",
    "topic_dist = softmax(doc_weights)\n",
    "\n",
    "# vector representation of the documents\n",
    "doc_vecs = np.matmul(topic_dist, topic_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.matmul(topic_vectors, resulted_word_vectors.T)\n",
    "most_similar = similarity.argsort(axis=1)[:, -30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "msl = list(map((lambda x: set(x)), most_similar.tolist()))\n",
    "ints = set.intersection(*msl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_n = list(map((lambda x: list(x - ints)), msl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  70,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  76,\n",
       "  13,\n",
       "  14,\n",
       "  16,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  86,\n",
       "  26,\n",
       "  28,\n",
       "  92,\n",
       "  33,\n",
       "  34,\n",
       "  40,\n",
       "  48,\n",
       "  241,\n",
       "  50,\n",
       "  58,\n",
       "  63],\n",
       " [1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  134,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  204,\n",
       "  141,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  84,\n",
       "  22,\n",
       "  23,\n",
       "  28,\n",
       "  30,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  42,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  51,\n",
       "  60],\n",
       " [65,\n",
       "  2,\n",
       "  6,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  75,\n",
       "  13,\n",
       "  14,\n",
       "  16,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  89,\n",
       "  30,\n",
       "  31,\n",
       "  57,\n",
       "  94,\n",
       "  164,\n",
       "  37,\n",
       "  38,\n",
       "  101,\n",
       "  49,\n",
       "  565,\n",
       "  53,\n",
       "  631,\n",
       "  441,\n",
       "  383],\n",
       " [129,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  9,\n",
       "  74,\n",
       "  11,\n",
       "  76,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  145,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  81,\n",
       "  26,\n",
       "  28,\n",
       "  34,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  50,\n",
       "  114,\n",
       "  185],\n",
       " [128,\n",
       "  1,\n",
       "  3,\n",
       "  64,\n",
       "  5,\n",
       "  6,\n",
       "  69,\n",
       "  73,\n",
       "  12,\n",
       "  13,\n",
       "  144,\n",
       "  18,\n",
       "  19,\n",
       "  25,\n",
       "  545,\n",
       "  229,\n",
       "  39,\n",
       "  553,\n",
       "  43,\n",
       "  44,\n",
       "  235,\n",
       "  111,\n",
       "  304,\n",
       "  368,\n",
       "  239,\n",
       "  180,\n",
       "  54,\n",
       "  119,\n",
       "  62],\n",
       " [1,\n",
       "  2,\n",
       "  4,\n",
       "  7,\n",
       "  135,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  147,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  84,\n",
       "  85,\n",
       "  213,\n",
       "  30,\n",
       "  31,\n",
       "  161,\n",
       "  37,\n",
       "  38,\n",
       "  42,\n",
       "  236,\n",
       "  50,\n",
       "  53],\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  132,\n",
       "  5,\n",
       "  7,\n",
       "  198,\n",
       "  137,\n",
       "  10,\n",
       "  203,\n",
       "  12,\n",
       "  17,\n",
       "  19,\n",
       "  20,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  155,\n",
       "  28,\n",
       "  27,\n",
       "  221,\n",
       "  34,\n",
       "  35,\n",
       "  100,\n",
       "  40,\n",
       "  48,\n",
       "  51,\n",
       "  58],\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  64,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  139,\n",
       "  69,\n",
       "  13,\n",
       "  14,\n",
       "  76,\n",
       "  16,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  24,\n",
       "  28,\n",
       "  34,\n",
       "  35,\n",
       "  44,\n",
       "  48,\n",
       "  51,\n",
       "  61],\n",
       " [1,\n",
       "  642,\n",
       "  3,\n",
       "  64,\n",
       "  6,\n",
       "  73,\n",
       "  12,\n",
       "  269,\n",
       "  13,\n",
       "  206,\n",
       "  18,\n",
       "  19,\n",
       "  469,\n",
       "  25,\n",
       "  282,\n",
       "  220,\n",
       "  29,\n",
       "  348,\n",
       "  420,\n",
       "  229,\n",
       "  39,\n",
       "  104,\n",
       "  489,\n",
       "  106,\n",
       "  43,\n",
       "  44,\n",
       "  119,\n",
       "  56,\n",
       "  255],\n",
       " [1,\n",
       "  2,\n",
       "  4,\n",
       "  325,\n",
       "  8,\n",
       "  140,\n",
       "  15,\n",
       "  82,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  156,\n",
       "  31,\n",
       "  96,\n",
       "  34,\n",
       "  36,\n",
       "  103,\n",
       "  360,\n",
       "  171,\n",
       "  45,\n",
       "  46,\n",
       "  176,\n",
       "  49,\n",
       "  306,\n",
       "  112,\n",
       "  371,\n",
       "  243,\n",
       "  121,\n",
       "  127]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1 : bad thing country life speak come talk love stand american time work go know good get want need fire real president think america people obama say mexican like amp\n",
      "topic 2 : latino truth speak tcot support win makeamericagreatagain tell candidate run american go know party want republican need leader voter president think america vote people democrat say gop like amp\n",
      "topic 3 : piece club slogan presidential apparent new lol man great see mouth campaign candidate run donaldtrumpforpresident go know good get want need fire way president think america nbc like hair\n",
      "topic 4 : wall pay country come man great talk american time white go know good get mexico kill illegal want need real president big america people say amp mexican like build\n",
      "topic 5 : business drop cut follow relationship recent sever ass company macys tie nbcuniversal univision pull officially comment mexico racist late fire immigrant remark call nbc say dump mexican amp end\n",
      "topic 6 : presidential country elect win man great potus candidate run clinton money party go know good get hillary want republican need president vote think america hell people gop like amp\n",
      "topic 7 : thing truth speak come send tell talk alien immigration american problem right go know get mexico illegal immigrant crime think mean criminal people say wrong gop mexican like amp\n",
      "topic 8 : job truth speak macys tell talk american right know good get mexico racist want real need fire call point think america vote people dump say gop mexican like amp\n",
      "topic 9 : missuniverse miss drop macys tie pageant distance missusa univision pull derogatory cancel usa universe air comment offensive mexico racist anti fire host immigrant remark nbc dump mexican controversial amp\n",
      "topic 10 : available spread place second lead national new jeb support look debate primary jebbush poll talk tee candidate attack immigration go get week republican bush vote movement gop like amp\n"
     ]
    }
   ],
   "source": [
    "# similarity = np.matmul(topic_vectors, resulted_word_vectors.T)\n",
    "# most_similar = similarity.argsort(axis=1)[:, -10:]\n",
    "\n",
    "for j in range(n_topics):\n",
    "#     topic_words_list = \n",
    "    topic_words = ' '.join([decoder[i] for i in reversed(most_similar_n[j])])\n",
    "    print('topic', j + 1, ':', topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show learned document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "X = tsne.fit_transform(doc_vecs.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X):\n",
    "    # X has shape [n_documents, 2]\n",
    "    \n",
    "    plt.figure(figsize=(16, 9), dpi=120);\n",
    "    cmap = plt.cm.tab20\n",
    "    number_of_targets = 3\n",
    "    \n",
    "    for i in range(number_of_targets):\n",
    "        \n",
    "        label = target_names[i]\n",
    "        size = 15.0\n",
    "        linewidths = 0.5\n",
    "        edgecolors = 'k'\n",
    "        color = cmap(i)\n",
    "        \n",
    "        if 'comp' in label:\n",
    "            marker = 'x'\n",
    "        elif 'sport' in label:\n",
    "            marker = 's'\n",
    "            edgecolors = 'b'\n",
    "        elif 'politics' in label:\n",
    "            marker = 'o'\n",
    "            edgecolors = 'g'\n",
    "        elif 'religion' in label:\n",
    "            marker = 'P'\n",
    "            size = 17.0\n",
    "        elif 'sci' in label:\n",
    "            marker = 'o'\n",
    "            size = 14.0\n",
    "            edgecolors = 'k'\n",
    "            linewidths = 1.0\n",
    "        elif 'atheism' in label:\n",
    "            marker = 'P'\n",
    "            size = 18.0\n",
    "            edgecolors = 'r'\n",
    "            linewidths = 0.5\n",
    "        else:\n",
    "            marker = 'v'\n",
    "            edgecolors = 'm'\n",
    "        \n",
    "        plt.scatter(\n",
    "            X[targets == i, 0], \n",
    "            X[targets == i, 1], \n",
    "            s=size, c=color, marker=marker,\n",
    "            linewidths=linewidths, edgecolors=edgecolors,\n",
    "            label=label\n",
    "        );\n",
    "    \n",
    "    leg = plt.legend()\n",
    "    leg.get_frame().set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(X)  # learned document vectors\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show initial document weights (vanilla lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_weights_init = np.load('doc_weights_init.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-fff0c169d7f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_weights_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch_custom/lib/python3.6/site-packages/MulticoreTSNE/__init__.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, _y)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_custom/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_custom/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "Y = tsne.fit_transform(doc_weights_init.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to initialize topic assignments for lda2vec algorithm \n",
    "# I run normal LDA and used output distributions over topics \n",
    "# of each document\n",
    "\n",
    "plot(Y)  # distribution over the topics for each document (output of LDA)\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore learned topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=200, n_jobs=4)\n",
    "Z = tsne.fit_transform(topic_dist.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Z)  # learned distribution over the topics for each document\n",
    "\n",
    "# these are topic assignments as on the plot above \n",
    "# but these ones are after the training of lda2vec\n",
    "\n",
    "# different colors and markers represent \n",
    "# ground truth labels of each document\n",
    "\n",
    "# open this image in new tab to see it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of nonzero probabilities\n",
    "dist = topic_dist.reshape(-1)\n",
    "plt.hist(dist[dist > 0.01], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of probabilities for some random topic\n",
    "plt.hist(topic_dist[:, 10], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic assignments for two random topics\n",
    "plt.scatter(topic_dist[:, 10], topic_dist[:, 20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of topic assignments\n",
    "corr = np.corrcoef(topic_dist.transpose(1, 0))\n",
    "plt.imshow(corr);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show a document and its topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT:\n",
      "269\n",
      "[-0.17874435 -0.02110231  0.10985541  0.11945958 -0.1667027   0.15010776\n",
      " -0.11709902  0.142265   -0.07686004 -0.16921599  0.1240266  -0.11825462\n",
      " -0.09898441 -0.08517006 -0.12140565 -0.09969614  0.07401945  0.13598673\n",
      "  0.16557884  0.09224206 -0.05806314  0.07982362 -0.14151505 -0.14326194\n",
      " -0.09792229 -0.03457102  0.11040005 -0.2025312  -0.11079633  0.08063796\n",
      " -0.1334653   0.18217127  0.0946084   0.16695362  0.10984115  0.04027427\n",
      " -0.06614006  0.18381554  0.05597054  0.16237077  0.08985563 -0.11956751\n",
      "  0.14351575 -0.10284287 -0.1738466   0.06360093  0.18626697  0.06131935\n",
      "  0.15995845 -0.10352875]\n",
      "50\n",
      "did you know that the u.s constitution is now under full pledge attack by the obama tyrant administration? wethepeople semst test\n",
      "DISTRIBUTION OVER TOPICS:\n",
      "1:0.041  2:0.043  3:0.047  4:0.046  5:0.037  6:0.041  \n",
      "7:0.037  8:0.039  9:0.038  10:0.041  11:0.037  12:0.043  \n",
      "13:0.039  14:0.039  15:0.039  16:0.042  17:0.039  18:0.040  \n",
      "19:0.035  20:0.042  21:0.039  22:0.038  23:0.039  24:0.037  \n",
      "25:0.042  \n",
      "\n",
      "TOP TOPICS:\n",
      "topic 3 : semst trump tcot people trade vote state offend latino follow title donaldtrump fund makeamericagreatagain call future amp constitution start come white candidate support believe america election rapist win black plan\n",
      "topic 4 : semst donaldtrump hate follow need right people time vote obama truth speak offend agree trump tcot government go house ill american get today patriot know trumpforpresident fire constitution job country\n",
      "topic 12 : donaldtrump semst blame obama gop thing trump tcot believe hillaryclinton dump want baltimoreriot talk trade president go know illegal win univision constitution way time call right hell attack pbo get\n"
     ]
    }
   ],
   "source": [
    "i = 200 # document id\n",
    "print('DOCUMENT:')\n",
    "for j, doc, type in docs:\n",
    "    if (doc_decoder[i] == int(j)):\n",
    "        print(j)\n",
    "        print(doc_vecs[i])\n",
    "        print(len(doc_vecs[i]))\n",
    "        print(doc, type)\n",
    "        break\n",
    "        \n",
    "\n",
    "# print([doc for j, doc, _ in docs if j == doc_decoder[i]][0], '\\n')\n",
    "\n",
    "print('DISTRIBUTION OVER TOPICS:')\n",
    "s = ''\n",
    "for j, p in enumerate(topic_dist[i], 1):\n",
    "    s += '{0}:{1:.3f}  '.format(j, p)\n",
    "    if j%6 == 0:\n",
    "        s += '\\n'\n",
    "print(s)\n",
    "\n",
    "print('\\nTOP TOPICS:')\n",
    "for j in reversed(topic_dist[i].argsort()[-3:]):\n",
    "    topic_words = ' '.join([decoder[i] for i in reversed(most_similar[j])])\n",
    "    print('topic', j + 1, ':', topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
